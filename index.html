<!DOCTYPE html>
<!-- Template by Quackit.com -->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">


    <title>Information Processing Lab</title>

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.3/css/bootstrap.min.css" integrity="sha384-MIwDKRSSImVFAZCVLtU0LMDdON6KVCrZHyVQQj6e8wIEJkW4tvwqXrbMIya1vriY" crossorigin="anonymous">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uHw+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

    <link rel="stylesheet" href="assets/css/main.css"/>

  </head>

  <body data-spy="scroll" data-target="#topNav">

    <nav id="topNav" class="navbar navbar-full navbar-fixed-top navbar-dark" style="background-color: #4b2e83;">
        <div class="container">
            <button class="navbar-toggler hidden-md-up pull-right" type="button" data-toggle="collapse" data-target="#collapsingNavbar">
                &#9776;
            </button>
            <a class="navbar-brand" href="index.html">
                <img src="images/logo/ipl-logo-white-50x30.png">
            </a>
            <div class="collapse navbar-toggleable-sm" id="collapsingNavbar">
                <ul class="nav navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="people.html">People</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link" href="projects.html">Projects</a>
                    </li> -->
                    <li class="nav-item">
                        <a class="nav-link" href="publication.html">Publication</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/ipl-uw" target="_blank">Software</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="life.html">Life</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="jumbotron jumbotron-billboard">
        <div class="img"></div>
        <div class="container jumbotron-title">
            <div class="row">
                <div class="col-lg-12">
                    <h1 class="display-4"><strong>Information Processing Lab</strong></h1>
                    <br>
                    <h4>
                        <i class="fas fa-university"></i> University of Washington 
                        &nbsp;&nbsp;
                        <i class="fas fa-map-marker-alt"></i> Seattle, WA
                    </h4>
                    <br>
                    <p class="lead">
                        Main research thrust of our current work is in the multimedia signal processing,
                        multimedia networking and machine learning areas. A specific focus is on the large scale smart
                        camera networks analytics and networking. The research group works under the guidance of
                        <a href="https://people.ece.uw.edu/hwang/" target="_blank">Prof. Jenq-Neng Hwang</a>.
                    </p>
                    <!-- <br><a href="#" class="btn btn-success btn-lg">Sign Up</a> -->
                </div>
            </div>
        </div>
    </div>

    <div class="container">
        <section id="news">
            <h2 class="display-4">News</h2><br>
            <ul class="news-bullet">
                <li>
                  <span class="tag tag-pill tag-success">2025/8/08</span>
                     Our paper "UniHPR: Unified Human Pose Representation via Singular Value Contrastive Learning" received the IEEE MIPR 2025 Best Paper Award. Congrats to Zhongyu!
                     <p align="center"><img src="images/news/unihpe.png" alt="" style="width:500px;border:1px solid;"></p> 
                </li>
                <li>
                  <span class="tag tag-pill tag-success">2025/6/30</span>
                     Our team won the 1st place of the 2025 AI City Challenge-Track 3: Warehouse Spatial Intelligence. Congrats to the team!
                </li>
                <li>
                  <span class="tag tag-pill tag-success">2025/6/30</span>
                     One paper has been accepted for oral presentation by IROS 2025!
                </li>
                <li>
                  <span class="tag tag-pill tag-success">2025/5/20</span>
                      One paper has been accepted for presentation at IEEE MIPR 2025! 
                </li>
                <li>
                  <span class="tag tag-pill tag-success">2025/5/19</span>
                      One paper has been accepted for presentation at IEEE AVSS 2025!
                </li>
              <li>
                <span class="tag tag-pill tag-success">2025/3/22</span>
                    One paper has been accepted for presentation at IEEE ICME 2025!
              </li>
              <li>
                <span class="tag tag-pill tag-success">2025/3/19</span>
                 Zhongyu successfully defended his Ph.D. thesis: "Towards Robust and Effective Human Pose Estimation and Generation" today. Congratulation! Dr. Jiang! 🎉🎉🎉
              </li>
              <li>
                <span class="tag tag-pill tag-success">2025/2/26</span>
                    Three papers has been accepted for presentation at IEEE CVPR 2025! Congratulation to the authors!
              </li>
               <li>
                  <span class="tag tag-pill tag-success">2024/10/07</span>
                    Our team won the 1st place of ICPR 2024 Multi-Modal Visual Pattern Recognition Challenge-Track 1: Tracking. Congrats to the team!
                   <p align="center"><img src="images/news/tracking1 uwipl_etri.jpg" alt="" style="width:500px;border:1px solid;"></p> 
               </li>
                <li>
                  <span class="tag tag-pill tag-success">2024/6/30</span>
                    Our team won the 3rd place of the IEEE Computational Intelligence in Biomedicine and Healthcare (CIS) Competition 2024. Congrats to the team!
                  <p align="center"><img src="images/news/cis_comp.jpg" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2024/6/06</span>
                        A paper has been accepted for presentation at IEEE ICIP 2024! Congratulation to Andy!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2024/6/04</span>
                    Jie successfully defended his Ph.D. thesis: "Continual Learning of Object Classification in the Real World" today. Congratulation! Dr. Mei! 🎉🎉🎉
                    <p align="center"><img src="images/news/jie_defense.jpg" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2024/3/30</span>
                        Two papers have been accepted for presentation at IEEE IV 2024! Congratulation to Sheng Yao and Andy!
                </li>
              
                <li>
                    <span class="tag tag-pill tag-success">2024/3/28</span>
                    Check out Professor Jenq-Neng Hwang's <a href="https://www.washington.edu/news/2024/03/28/train-ai-machine-learning-when-you-dont-have-enough-data/">latest interview on AI innovation</a>: tackling the challenge of training algorithms with limited data, his team at the University of Washington is pioneering methods to enhance AI's learning curve, from monitoring baby poses to diagnosing rare diseases. 
                </li>
              
                <li>
                    <span class="tag tag-pill tag-success">2024/1/07</span>
                    Our team representing the UWIPL is the Winner of both <a href="https://macvi.org/workshop/macvi24/challenges/uav_track">UAV-based Multi-Object Tracking with Reidentification</a> and <a href="https://macvi.org/workshop/macvi24/challenges/usv_track">USV-based Multi-Object Tracking</a> track at the <a href="https://macvi.org/workshop/macvi24/challenges/">2nd Workshop on Maritime Computer Vision (MaCVi)</a> in WACV.
                   <p align="center"><img src="images/news/MaCVi_UAV.jpg" alt="" style="width:320px;border:1px solid;height:260px;">  <img src="images/news/MaCVi_USV.jpg" alt="" style="width:320px;border:1px solid;height:260px;"> <img src="images/news/macvi_winning_photo.jpg" alt="" style="width:320px;border:1px solid;height:260px;"> </p>
                </li>
        
                <li>
                    <span class="tag tag-pill tag-success">2023/12/16</span>
                        Three papers have been accepted for presentation at IEEE ICASSP 2024! Congratulation to Chris, Zhongyu and Jie!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2023/11/18</span>
                    <i>SLVP: Self-supervised Language-Video Pre-training for Referring Video Object Segmentation</i> was accepted by the WACV 2024 - <a href="https://sites.google.com/illinois.edu/pretraining-lm-workshop-wacv24/">2nd Workshop on Pretraining</a>! Congratulation to <a href="https://jay-ipl.github.io/">Jie</a>!
                                      <p align="center"><img src="images/news/slvp demo.gif" alt="" style="width:250px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2023/10/25</span>
                    <a href="https://github.com/ipl-uw/ZeDO-Release"><i>Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation</i></a> was accepted by the WACV 2024! Congratulation to Zhongyu!
                                      <p align="center"><img src="images/news/zedo_overall.png" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2023/06/21</span>
                      Three papers have been accepted for presentation at IEEE ICIP 2023!
                </li>
                <li>
                  <span class="tag tag-pill tag-success">2023/06/19</span>
                      Our team representing the UW-ETRI is the Winner of Track 1 (Multi-Camera People Tracking) at the <a href="https://www.aicitychallenge.org/">AI City Challenge</a> in <a href="http://cvpr2023.thecvf.com/">CVPR 2023</a>.
                    <p align="center"><img src="images\news\2023-06-20-cvpr23-AICity.jpg" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/12/07</span>
                    Haotian successfully defended his Ph.D. thesis: "Inferring the 3D Information from the Outside World Using Monocular Cameras" today. Congratulation! Dr. Zhang! 🎉🎉🎉
                    <p align="center"><img src="images/news/haotian_defense.JPG" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/12/06</span>
                    Yizhou successfully defended his Ph.D. thesis: "Object 3D Perception via Camera-Radar Cross-Modality Learning for Autonomous Driving" today. Congratulation! Dr. Wang! 🎉🎉🎉
                    <p align="center"><img src="images/news/yizhou_defense.PNG" alt="" style="width:500px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/12/06</span>
                    We welcome everyone to join the three guest lectures presented by Professor Ming-Hsuan Yang, please refer to the posters for more info!
                        <p align="center"><img src="images/news/202212_talk_2.JPG" alt="" style="width:320px;border:1px solid;height:420px;">  <img src="images/news/202212_talk_1.JPG" alt="" style="width:320px;border:1px solid;height:420px;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/11/17</span>
                      <i>Observation Centric and Central Distance Recovery for Athlete Tracking</i> has been accepted for presentation at the 2nd Workshop on Computer Vision for Winter Sports held in conjunction with WACV 2023! Congratulation to Hsiang-Wei and Chris!
                  </li>
                  <li>
                    <span class="tag tag-pill tag-success">2022/10/23</span>
                    Our team won the 3rd place of the SportsMOT Track of DeeperAction Challenge at ECCV 2022! Congraulations to Hsiang-Wei, Chris and Dr.Kim!
                                      <p align="center"><img src="images/news/DeepActionTrack3.png" alt="" style="width:500px;border:1px solid;"></p>

                </li>
              <li>
                <span class="tag tag-pill tag-success">2022/10/10</span>
                  <i>CameraPose: Weakly-Supervised In-the-wild 3D Human Pose Estimation from a Single Image</i> was accepted by the WACV 2023! Congratulation to Chris!
              </li>
               <li>
                    <span class="tag tag-pill tag-success">2022/10/10</span>
                    <i>HuPR: A Benchmark for Human Pose Estimation Using Millimeter Wave Radar</i> was accepted by the WACV 2023! Congratulation to Robert!
                </li>
              <li>
                <span class="tag tag-pill tag-success">2022/10/08</span>
                Haotian has been selected as one of the Young Scholar Award recipients for this year's NeurIPS! Congratulation!
              </li>
              <li>
                    <span class="tag tag-pill tag-success">2022/09/14</span>
                    <i>GLIPv2: Unifying Localization and Vision-Language Understanding</i> was accepted by the NeurIPS 2022 (25.6% acceptance rate)! Congratulation to Haotian!!!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/21</span>
                    <i>Grounded Language-Image Pre-training</i> was selected as the one of the 33 finalists for the Best Paper Award at CVPR 2022! 
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/20</span>
                    <i>GaitTAKE: Gait Recognition by Temporal Attention and Keypoint-guided Embedding</i> was accepted by the IEEE International Conference on Image Processing! Congratulation to Dr.Hsu, Yizhou and Chris!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/20</span>
                    <a href="https://arxiv.org/abs/2202.13018"><i>HCIL: Hierarchical Class Incremental Learning for Longline Fishing Visual Monitoring</i> </a> was accepted by the IEEE International Conference on Image Processing! Congratulation to <a href="https://jay-ipl.github.io/">Jie</a>!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/03</span>
                    Jiarui successfully defended her Ph.D. thesis: "Towards visual recognition in the wild." today! Congratulations to
                    Dr.Cai 👩🏻‍🎓! 🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/05/23</span>
                    We'll like share the news that <a href="https://attend.ieee.org/mmsp-2022/call-for-papers/">IEEE MMSP 2022</a>, which will be held on September 26–28, 2022 in Shanghai, China is now calling for paper!
                        <p align="center"><img src="images/news/MMSP2022-CFP.png" alt="" style="width:500px;border:1px solid;height:600px;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/05/16</span>
                        We are pleased to share the news the the Data Scientist/AI/ML position (The <a href="https://www.usajobs.gov/job/654683600/print">DE</a> and <a href="https://www.usajobs.gov/job/654681800/print">MAP</a> announcements for the  Interdisciplinary Computer Scientist/Physical Scientist/Fish Biologist, ZP-1550/1301/0482-3/4) in the FATES Advanced Tech Branch has been posted.
                        The announcements will be open for 14- days, from 05/17/22 to 05/30/22, please refer to the links for additional info!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/04/25</span>
                    <a href="https://arxiv.org/abs/2201.09373"> <i>Unsupervised Severely Deformed Mesh Reconstruction (DMR) from a Single-View Image for Longline Fishing</i> </a> was accepted by the IEEE ICME 2022 Workshop on 3D Multimedia Analytics, Search and Generation (3DMM)! Congratulation to <a href="https://jay-ipl.github.io/">Jie</a>!
                        <p align="center"><img src="images/news/3d_fish.gif" alt="" style="width:300px;border:1px solid;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/04/25</span>
                        <i>GolfPose: Golf Swing Analyses with A Monocular Camera based Human Pose Estimation</i> was accepted by the IEEE ICME 2022: The 3rd Artificial Intelligence in Sports (AI-Sports) Workshop! Congratulation to Zhongyu and Haorui!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/03/06</span>
                    <i>Unsupervised Domain Adaptation Learning for Infant Pose Recognition with Synthetic Data</i> was accepted by the IEEE ICME 2022 (29% acceptance rate)! Congratulation to Chris and Zhongyu!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/03/02</span>
                    <i>Grounded Language-Image Pre-training</i> was accepted by the CVPR 2022 (25.33% acceptance rate)! Congratulation to Haotian!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/12/01</span>
                    <i>LUNA: Localizing Unfamiliarity Near Acquaintance for Open-set Long-Tailed Recognition</i> was accepted by the AAAI 2022 (15% acceptance rate)! Congratulation to Jiarui, Yizhou and Hung-Min!
                </li>
                <li>
                <li>
                    <span class="tag tag-pill tag-success">2021/10/17</span>
                    Our team is the 🏆winner of Video Track (in both MOTChallenge-STEP and KITTI-STEP dataset) in the
                    <a href="https://motchallenge.net/workshops/bmtt2021/">6th BMTT Challenge</a> (in conjunction with ICCV 2021)!
                    <div class="row">
                        <div class="imgContainer">
                            <p align="center"><img src="images/news/bmtt2021_mots.png" alt="" style="height:200px;border: 1px solid"></p>
                        </div>
                        <div class="imgContainer">
                            <p align="center"><img src="images/news/bmtt2021_kitti.png" alt="" style="height:200px;border: 1px solid"></p>
                        </div>                    
                    </div>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/10/16</span>
                    Our team won the 🥉3rd place of Camera-View Track in the
                    <a href="https://iccv2021-mmp.github.io/">ICCV 2021 Multi-camera Multiple People Tracking Workshop </a>!
                    <p align="center"><img src="images/news/mmp2021_certificate.png" alt="" style="width:350px;border:1px solid"></p>
                    <p align="center"><img src="images/news/mmp2021.gif" alt="" style="width:500px;height:;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/09/09</span> Professor Hwang will be the guest editor for a special issue: <a href="https://www.mdpi.com/journal/applsci/special_issues/DL_Multi_Data">"Deep Learning from Multi-Sourced Data" for Applied Sciences</a>. Welcome to submitted original research, applications, and review articles in all areas related to learning from multi-souced data!
                    <p align="center"><img src="images/news/cfp_AS_SI.JPG" alt="" style="width:500px;border:1px solid;height:600px;"></p>

                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/08/09</span>
                    Li Chen successfully defended his Ph.D. thesis today. Congratulations to
                    Dr. Chen! 🎉🎉🎉
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/07/22</span>
                    Two papers from IPL:
                    <i>ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot (Oral)</i>
                    and
                    <i>Track without Appearance: Learn Box and Tracklet Embedding with Local and Global Motion Patterns for Vehicle Tracking</i>
                    were accepted and select as oral by the ICCV 2021! Congratuations Jiarui and Gaoang!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/03/22</span>
                    We won the Honorable Mention Award in NTIRE 2021 Challenge on Multi-modal Aerial View Object Classification (in conjunction with CVPR 2021)!
                    <p align="center"><img src="images/news/ntire2021_certificate.png" alt="" style="width:350px;border:1px solid"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/01/01</span>
                    We are organizing the Radar Object Detection Challenge (ROD2021) at <a href="http://icmr2021.org/challenges.html">ACM ICMR 2021</a>. Welcome your participation! <a href="https://www.cruwdataset.org/rod2021">[Challenge Website]</a> <a href="https://competitions.codalab.org/competitions/28019">[Registration & Leaderboard]</a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/06/11</span>
                    Our team is the winner of track 3 (multi-object tracking and segmentation in KITTI-MOTS and MOTS20 dataset with public detection)
                    and the runner-up of track 2 (multi-object detection, tracking and segmentation in KITTI-MOTS dataset) in the
                    5th BMTT Challenge</a> in CVPR 2020 workshop. <a href="news/2020-06-11-cvpr20-bmtt.html">[Details...]</a>
                    <p align="center"><img src="images/news/bmtt2020.png" alt="" style="width:300px;border:1px solid"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/06/05</span>
                    Renshu Gu successfully defended her Ph.D. thesis today. Congratulations to Dr. Gu! 🎉🎉🎉
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/05/04</span>
                    Li Chen and his colleagues in <a href="https://rad.washington.edu/research/groups/vascular-imaging-laboratory/">Vascular Imaging Laboratory</a> won the <a href="https://newsroom.heart.org/news/seattle-scientist-wins-competition-for-artificial-intelligence-research">competition</a> for artificial intelligence research by American Heart Association and Amazon Web Services through a collaborative data grant initiative (Automated Vessel Wall Screening to Predict Cardiovascular Risk) funded by AHA. Congatulations, Li!
                    <br>
                    <a href="https://newsroom.uw.edu/postscript/knee-mris-can-depict-cardiovascular-risk-ai-affirms-it" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> UW Daily News</span></a>
                    <a href="https://www.radiologybusiness.com/topics/artificial-intelligence/radiology-amazon-american-heart-association-mri" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Media Cover</span></a>

                </li>

                <li>
                    <span class="tag tag-pill tag-success">2019/10/25</span>
                    Three papers from IPL:
                    <i>Eye in the Sky: Drone-Based Object Tracking and 3D Localization</i>,
                    <i>Monocular Visual Object 3D Localization in Road Scenes</i>
                    <a href="http://yizhouwang.net/blog/2019/07/15/object-3d-localization/" target="_blank"><i class="fas fa-link"></i></a>,
                    <i>Exploit the connectivity: Multi-object tracking with trackletnet</i> are accepted as orals in
                    <a href="https://acmmm.org/">ACM MultiMedia 2019</a>.
                    Congratuations Haotian, Yizhou and Gaoang! 👍
                    <br>
                    <a href="https://dl.acm.org/citation.cfm?doid=3343031.3350924" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Eye in the Sky </span></a>
                    <a href="https://arxiv.org/pdf/1910.08259.pdf" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Object 3D Localization </span></a>
                    <a href="https://arxiv.org/abs/1811.07258" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> TrackletNet</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/06/16</span>
                    Our team representing the University of Washington is the Winner of Track 1 (City-Scale Multi-Camera Vehicle Tracking) and the Runner-up of Track 2 (City-Scale Multi-Camera Vehicle Re-Identification) and Track 3 (Traffic Anomaly Detection) at the <a href="https://www.aicitychallenge.org/">AI City Challenge</a> in <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>. 
                    <a href="news/2019-06-16-cvpr19-aicity.html">[Details...]</a>
                    <br>
                    <a href="https://www.ece.uw.edu/spotlight/ece-team-wins-competition-in-ai-challenges/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> UWECE News</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/06/15</span>
                    Three Ph.D. graduate from our lab this year. Congratulations to Dr. Tang, Dr. Wang, and Dr. Huang! 🎉🎉🎉 
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/04/01</span>
                    Professor Hwang is interviewed by The Wall Street Journal. 
                    <a href="news/2019-04-01-hwang-wsj-full-text.html">[Full Text]</a>
                    <br>
                    <a href="https://www.wsj.com/articles/how-many-fish-are-there-in-the-sea-ai-can-find-the-answer-11554155162"><span class="tag tag-pill tag-default"><i class="fas fa-link"></i> WSJ Article</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2018/06/18</span>
                    Our team representing the University of Washington is the Winner of Track 1 (Traffic Flow Analysis) and the Winner of Track 3 (Multi-camera Vehicle Detection and Reidentification) at the <a href="https://www.aicitychallenge.org/">AI City Challenge Workshop</a> at <a href="http://cvpr2018.thecvf.com/">CVPR 2018</a>. 
                    <a href="news/2018-06-18-aic-cvpr-2018.html">[Details...]</a>
                    <br>
                    <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Tang_Single-Camera_and_Inter-Camera_CVPR_2018_paper.pdf"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Paper</span></a>
                    <a href="https://github.com/zhengthomastang/2018AICity_TeamUW"><span class="tag tag-pill tag-default"><i class="fas fa-code"></i> Code</span></a>
                    <a href="https://youtu.be/_i4numqiv7Y"><span class="tag tag-pill tag-default"><i class="fas fa-video"></i> Track1 Demo</span></a>
                    <a href="https://youtu.be/Jlvh_KxHl40"><span class="tag tag-pill tag-default"><i class="fas fa-video"></i> Track3 Demo</span></a>
                    <a href="http://www.ee.washington.edu/spotlight/hwangs-team-beats-out-the-competition-in-ai-challenges/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> UWEE News</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2017/08/05</span>
                    Our group is the Winner of Track 2 (AI City Applications Track) at the <a href="http://smart-city-conference.com/AICityChallenge/">2017 IEEE Smart World NVIDIA AI City Challenge</a>. 
                    <a href="news/2017-08-05-aic-2017.html">[Details...]</a>
                    <br>
                    <a href="https://blogs.nvidia.com/blog/2017/08/09/ai-city-challenge/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> Nvidia Blog</span></a>
                </li>
            </ul>
            <br><br>
        </section>
    </div>

    <div class="footer" style="text-align:center;">
    <br>
    <p>&copy; 2021 IPL@UW</p>
    
    <!-- Visitor Counter -->
    <div id="sfcmb8j91dx75s27uay1qz75k3l6ye23856"></div>
    <script type="text/javascript" src="https://counter1.optistats.ovh/private/counter.js?c=mb8j91dx75s27uay1qz75k3l6ye23856&down=async" async></script>
    <noscript>
        <a href="https://www.freecounterstat.com" title="visitor counter for website">
            <img src="https://counter1.optistats.ovh/private/freecounterstat.php?c=mb8j91dx75s27uay1qz75k3l6ye23856" 
                 border="0" alt="visitor counter for website">
        </a>
    </noscript>
    
    <br>
    </div>



    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.0.0/jquery.min.js" integrity="sha384-THPy051/pYDQGanwU6poAc/hOdQxjnOEXzbT+OuUAFqNqFjL+4IGLBgCJC3ZOShY" crossorigin="anonymous"></script>

    <!-- Tether -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js" integrity="sha384-Plbmg8JY28KFelvJVai01l8WyZzrYWG825m+cZ0eDDS1f7d/js6ikvy1+X+guPIB" crossorigin="anonymous"></script>

    <!-- Latest compiled JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.3/js/bootstrap.min.js" integrity="sha384-ux8v3A6CPtOTqOzMKiuo3d/DomGaaClxFYdCu2HPMBEkf6x2xiDyJ7gkXU0MWwaD" crossorigin="anonymous"></script>

    <!-- Initialize Bootstrap functionality -->
    <script>
    // Initialize tooltip component
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })

    // Initialize popover component
    $(function () {
      $('[data-toggle="popover"]').popover()
    })
    </script>    

  </body>
</html>
